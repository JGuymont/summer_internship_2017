epsilon = rnorm(m ,mean=0, sd=Sigma)
design = matrix(cbind(1, training_years + 1, AccRain[,1], AccHDD, AccCDD, AccCDD^2), nrow = m, ncol = 6)
B = matrix(ols_param, nrow=6, ncol=1)
R = exp(as.vector(design %*% B)+epsilon)
par0 = c(0.25, 0.25, 0.25, 0.25, 100, 402, 50, 200)
COST = function(par0) cost(par0, R, AccRain, AccCDD, AccHDD, 'tvar', 0.10)
hedge = optim(par0, COST)
p = abs(hedge$par)
return(p)
})
sim_temp = sapply(1:m, simulate_temp)
sim_dat  = cbind(temp_data$Month[1:365], sim_temp)
AccCDD   = colSums(pmax(sim_dat[sim_dat[,1] %in% c(6,7,8),-c(1)]-18,0))
AccHDD   = colSums(pmax(18-sim_dat[sim_dat[,1] == 9,-c(1)],0))
AccRain  = rMvdc(m, copula_dist) # AccRain[1,]=QC, AccRain[2,]=Chicago
epsilon = rnorm(m ,mean=0, sd=Sigma)
design = matrix(cbind(1, training_years + 1, AccRain[,1], AccHDD, AccCDD, AccCDD^2), nrow = m, ncol = 6)
B = matrix(ols_param, nrow=6, ncol=1)
R = exp(as.vector(design %*% B)+epsilon)
par0 = c(0.25, 0.25, 0.25, 0.25, 100, 402, 50, 200)
COST = function(par0) cost(par0, R, AccRain, AccCDD, AccHDD, 'tvar', 0.10)
COST(par0)
cost(par0, R, AccRain, AccCDD, AccHDD, 'tvar', 0.10)
R
B
design
AccCDD
sim_dat
sim_temp
simulate_temp
sim_temp = sapply(1:m, simulate_temp)
sim_temp
sim_dat
s2
s1
skew
omega
alpha
beta
gamma
rho
M2s
sdhat
Ez
simulate_temp(1)
lag = (training_years*365 + 1):(training_years*365+P)
lag
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1:P] = log(sdhat[lag]^2)
lsigma2
sdhat
lag
lag = (training_years*365 - P):(training_years*365)
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1:P] = log(sdhat[lag]^2)
lag
lag = (training_years*365 - P + 1):(training_years*365)
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1:P] = log(sdhat[lag]^2)
lsigma2[1:P]
sim_deltaTemp = matrix(nr=365,nc=1)
sim_deltaTemp[1:P] = deltaTemp[lag]
lsigma2_init = log(sdhat[training_days -1]^2)
lsigma2_init
lsigma2[1] = log(sdhat[training_days -1]^2)
lag = ((training_years-1)*365 + 1):((training_years-1)*365+P)
lag
lsigma2[1] = log(sdhat[lag[3]]^2)
lsigma2 = vector(length = 365)
lsigma2[1] = log(sdhat[lag[3]]^2)
lsigma2
lsigma2[1]
sim_deltaTemp = matrix(nr=365,nc=1)
sim_deltaTemp[1:P] = deltaTemp[lag]
sim_deltaTemp[1:P]
sim_temp = vector(length = 365)
sim_temp[1:P] = temp_data$Mean[lag]
sim_temp[1:P]
source('~/Desktop/Machine Learning Project/Stage de recherche/hedging.R', echo=TRUE)
hyld = vector()
derivatives_profit = vector()
for (i in 1:num_sim){
K1 = round(abs(p[5,i])) # contract strikes
K2 = round(abs(p[6,i]))
K3 = round(abs(p[7,i]))
K4 = round(abs(p[8,i]))
# Profit/loss on contracts
W1 = p[1,i]*(pmax(annual_data$AccRain[training_years+1] -K1,0) - price_call_rain[price_call_rain[,1]== K1,2])
W2 = p[2,i]*(pmax(annual_data$AccCDD[training_years+1] - K2,0) - price_call_cdd[price_call_cdd[,1] == K2,2])
W3 = p[3,i]*(pmax(annual_data$AccHDD9[training_years+1] - K3,0) - price_call_hdd[price_call_hdd[,1] == K3,2])
W4 = p[4,i]*(pmax(K4-annual_data$AccCDD[training_years+1],0) - price_put_cdd[price_put_cdd[,1] == K4,2])
derivatives_profit[i] = W1+W2+W3+W4
hyld[i] = yld[training_years+1]+W1+W2+W3+W4 # hedged profits
}
hist(derivatives_profit)
mean_hyld = colMeans(hyld)
mean_hyld = colMeans(hyld)
mean_hyld = mean(hyld)
mean_hyld
yld[21]
x = 1:10 + rnorm(10)
x
x = 1:10
y = 2 + 0.5*x + rnorm(10)
fit = lm(y ~ x)
fit
fit_seatrend = lm(y ~ x)
fit_seatrend = lm(y ~ x)
fit_seatrend
predict.lm(fit_seatrend, 3)
y
predict.lm(object = fit_seatrend, newdata = 3)
predict.lm(object = fit_seatrend, newdata = c(3))
predict.lm(object = fit_seatrend, newdata = c(x_test))
x_test = 20
predict.lm(object = fit_seatrend, newdata = c(x_test))
x_test = 20
x_test
predict.lm(object = fit_seatrend, newdata = data.frame(x_test))
x_test = data.frame(11:20)
predict.lm(object = fit_seatrend, newdata = x_test)
predict.lm(object = lm(y ~ x), newdata = x_test)
predict.lm(lm(y ~ x), newdata = x_test)
x = 1:10
y = 2 + 0.5*x + rnorm(10)
x_test = data.frame(11:20)
fit_seatrend = lm(y ~ x)
predict.lm(lm(y ~ x), newdata = x_test)
y
x = 1:10
y = 1 + 1.5*x + rnorm(10)
x_test = data.frame(11:20)
fit_seatrend = lm(y ~ x)
predict.lm(lm(y ~ x), newdata = x_test)
y
x_test = data.frame(11:15)
fit_seatrend = lm(y ~ x)
predict.lm(lm(y ~ x), newdata = x_test)
predd = predict.lm(lm(y ~ x), newdata = x_test)
predd
x_test = data.frame(111:120)
fit_seatrend = lm(y ~ x)
predd = predict.lm(lm(y ~ x), newdata = x_test)
predd
x_test = data.frame(x = 111:120)
predd = predict.lm(lm(y ~ x), newdata = x_test)
predd
coef(seatrend_model)
seatrend_model = lm(Mean ~ t + Fourier(M1, lenght(training_days)), data = temp_data)
seatrend_model = lm(Mean ~ t + Fourier(M1, lenght(training_days)), data = temp_data)
lenght(training_days)
seatrend_model = lm(Mean ~ t + Fourier(M1, length(training_days)), data = temp_data)
length(training_days)
train_size = 20
training_days  = (21 - train_size + 1):21*365
seatrend_model = lm(Mean ~ 1:lenght(training_days)  + Fourier(M1, length(training_days)), data = temp_data)
seatrend_model = lm(Mean ~ 1:length(training_days)  + Fourier(M1, length(training_days)), data = temp_data)
length(training_days)
training_days  = (21 - train_size + 1):21*365
training_days
(21 - train_size + 1)
training_days  = ((21 - train_size)*365 + 1):21*365
training_days
(21 - train_size)
(21 - train_size)*365
((21 - train_size)*365 + 1)
21*365
training_days  = ((21 - train_size)*365 + 1):21*365
training_days
training_days  = ((21 - train_size)*365 + 1):(21*365)
training_days
seatrend_model = lm(Mean ~ t + Fourier(M1, length(training_days)), data = temp_data)
test_days = (21*365 + 1):(22*365)
four_terms = Fourier(M1, length(training_days)
seatrend_model = lm(Mean ~ t + ), data = temp_data)
four_terms = Fourier(M1, length(training_days)
seatrend_model = lm(Mean ~ t + four_terms), data = temp_data)
four_terms = Fourier(M1, length(training_days))
four_terms
seatrend_model = lm(Mean ~ t + four_terms, data = temp_data)
plot(colSums(four_terms))
plot(rowSums(four_terms), type = 'l')
seatrend_model = lm(Mean ~ t + four_terms, data = temp_data)
seatrend = fitted(seatrend_model, data.frame(t = ))
seatrend = fitted(seatrend_model)
seatrend_model = lm(Mean ~ t + four_terms, data = temp_data)
seatrend = fitted(seatrend_model)
predict.lm(seatrend_model, data.frame(t = test_days, four_terms = four_terms))
predict.lm(seatrend_model, data.frame(t = test_days, four_terms = four_terms[1:365,]))
test_days
seatrend_model$coefficients
matrix(seatrend_model$coefficients, nr = 8, nc =1)
matrix(cbind(1, test_days, four_terms[1:365,]), nr = 365, nc = 8)
matrix(cbind(1, test_days, four_terms[1:365,]), nr = 365, nc = 8) %*% matrix(seatrend_model$coefficients, nr = 8, nc =1)
seatrend[test_days] = matrix(cbind(1, test_days, four_terms[1:365,]), nr = 365, nc = 8) %*% matrix(seatrend_model$coefficients, nr = 8, nc =1)
plot(seatrend)
training_days  = ((21 - train_size)*365 + 1):(21*365)
training_days
21*365
(21*365 + 1)
test_days = (21*365 + 1):(22*365)
training_days  = ((21 - train_size)*365 + 1):(21*365)
seatrend = fitted(seatrend_model)
plot(seatrend)
deltaTemp = DAT - seatrend # remainder of the DAT once the mean is removed
bic_garch = function(par) Bic_Garch(par, deltaTemp, training_days) #
maxM2=6; maxP=4 # maximum orders to be tested.
order_comb = expand.grid(M2=1:maxM2,P=1:maxP) # matrix of all the combinations of M2 and P.
order_mean = matrix(apply(order_comb,1,bic_garch),nr=maxM2,nc=maxP) # bic_garch is applied to all the combinations (lines of order_comb).
Bic_Garch <- function(par, res, t){
l = length(t)
M2=par[1]
P=par[2]
cos.mtx <- matrix(nr=l,nc=M2)
sin.mtx <- matrix(nr=l,nc=M2)
X <- matrix(nr=l,nc=2*M2)
for (m in 1:M2){
X[,m] <- cos(2*pi*t*m/365)
X[,M2+m] <- sin(2*pi*t*m/365)
}
spec <- ugarchspec(
variance.model = list(model='eGARCH',external.regressors = X),
distribution.model = "snorm",
mean.model = list(armaOrder = c(P, 0),include.mean=FALSE),
start.pars = list(omega=1.1, alpha1=0.1,beta1=0.5))
egarchfit = ugarchfit(spec = spec, data = res)
k = length(coef(egarchfit))
bic <- k*log(l)-2*likelihood(egarchfit)
return(bic)
}
bic_garch = function(par) Bic_Garch(par, deltaTemp, training_days) #
maxM2=6; maxP=4 # maximum orders to be tested.
order_comb = expand.grid(M2=1:maxM2,P=1:maxP) # matrix of all the combinations of M2 and P.
order_mean = matrix(apply(order_comb,1,bic_garch),nr=maxM2,nc=maxP) # bic_garch is applied to all the combinations (lines of order_comb).
order_mean = as.numeric(which(order_mean == min(order_mean),arr.ind=TRUE)) # find the position of min(bic_garch). Row=M2, Column = P.
M2  = order_mean[1]
M2
P = order_mean[2]
P
spec = ugarchspec(
variance.model = list(model='eGARCH',external.regressors = Fourier(M2, lenght(training_days))), # There is a cyclical trend in the volatility
# so we had a Fourier to model the mean
distribution.model = "snorm", # the skewed normal seems to fit the residuals better than the normal
mean.model = list(armaOrder = c(P, 0), include.mean=FALSE), # P is the AR order of the series
start.pars = list(omega=1.1, alpha1=0.1,beta1=0.5)) # starting parameters have been determined previously and are sometimes
spec = ugarchspec(
variance.model = list(model='eGARCH',external.regressors = Fourier(M2, length(training_days))), # There is a cyclical trend in the volatility
# so we had a Fourier to model the mean
distribution.model = "snorm", # the skewed normal seems to fit the residuals better than the normal
mean.model = list(armaOrder = c(P, 0), include.mean=FALSE), # P is the AR order of the series
start.pars = list(omega=1.1, alpha1=0.1,beta1=0.5)) # starting parameters have been determined previously and are sometimes
egarchfit = ugarchfit(spec = spec, data = deltaTemp) # the algo that fit the GARCH is called here with parameters spec
coef_garch = data.frame(coef(egarchfit))
skew = coef_garch['skew',1] # parameter of the residuals distribution
omega = coef_garch['omega',1]  # omega, alpha1, beta1 and gamma are parameters of the eGARCH
alpha = coef_garch['alpha1',1]
beta  = coef_garch['beta1',1]
gamma = coef_garch['gamma1',1]
rho = matrix(coef_garch[1:P,1], nr=1,nc=P) # AR(P) coefficients
M2s = coef_garch[(P+5):(M2*2+P+4),1]
sdhat = as.numeric(sigma(egarchfit)) # estimated of the conditionnal standard deviation
s1 = matrix(cbind(1, test_days, four_terms[1:365,]), nr = 365, nc = 8) %*% matrix(seatrend_model$coefficients, nr = 8, nc =1) # the seasonal trend is deterministic. We used the last year of
s2 = colSums(M2s*t(Fourier(M2,length(training_days)))) # the seasonal trend in the volatility is also deterministic. s2
Ez=sqrt(2/pi) # E[|z|], z ~ skNormal(0,1, xi). E[|z|] is the expected value of eGARCH residuals.
Ez=sqrt(2/pi) # E[|z|], z ~ skNormal(0,1, xi). E[|z|] is the expected value of eGARCH residuals.
simulate_temp(1)
sim_dat = cbind(temp_data$Month[1:365],sapply(1:10000, simulate_temp))
AccCDD  = colSums(pmax(sim_dat[sim_dat[,1] %in% c(6,7,8),-c(1)]-18,0))
AccHDD  = colSums(pmax(18-sim_dat[sim_dat[,1] == 9,-c(1)],0))
AccRain = rgamma(m, shape = shape_qc, scale=scale_qc)
ep_call_cdd     = sapply(seq(0,500,1), function(x) expected_payoff(AccCDD, x, 'call'))
price_call_cdd  = cbind(K=seq(0,500,1), ep_call_cdd)
ep_put_cdd = sapply(seq(0, 500, 1), function(x) expected_payoff(AccCDD, x, 'put'))
price_put_cdd   = cbind(K=seq(0, 500, 1), ep_put_cdd)
ep_call_hdd = sapply(seq(0, 200, 1), function(x) expected_payoff(AccHDD, x, 'call'))
price_call_hdd  = cbind(K=seq(0, 200, 1), ep_call_hdd)
ep_call_rain = sapply(seq(0, 250, 1), function(x) expected_payoff(AccRain, x, 'call'))
price_call_rain = cbind(K=seq(0, 250, 1), ep_call_rain)
cl = makeCluster(detectCores()-1) # Start up a parallel cluster
print(cl)
cl_objects = list( 'temp_data','training_years','training_days','test_year','test_days',
# parameters
'ols_param','Sigma', 'P', 'M2','omega','alpha','beta','gamma','skew',
'rho','Ez', 'sdhat', 'm', 'num_sim',
# relevant series
's1', 's2', 'seatrend','deltaTemp',
# relevant functions
'copula_dist', 'simulate_temp', 'cost', 'tvar', 'svar',
# derivatives prices
'price_call_cdd', 'price_put_cdd', 'price_call_hdd', 'price_call_rain')
clusterExport(cl, cl_objects)
test_year = 22
test_days = (21*365 + 1):(22*365)
clusterExport(cl, cl_objects)
num_sim = 2
m = 10 # 'm' is the number of temperature simulation used
if(!is.null(cl)) {
stopCluster(cl)
cl = c()
}
fGarch
print(cl)
library(fGarch)
num_sim
m
cl = makeCluster(detectCores()-1) # Start up a parallel cluster
print(cl)
cl_objects = list( 'temp_data','training_years','training_days','test_year','test_days',
# parameters
'ols_param','Sigma', 'P', 'M2','omega','alpha','beta','gamma','skew',
'rho','Ez', 'sdhat', 'm', 'num_sim',
# relevant series
's1', 's2', 'seatrend','deltaTemp',
# relevant functions
'copula_dist', 'simulate_temp', 'cost', 'tvar', 'svar',
# derivatives prices
'price_call_cdd', 'price_put_cdd', 'price_call_hdd', 'price_call_rain')
clusterExport(cl, cl_objects)
p = parSapply(cl, 1:num_sim, function(i) {
library(fGarch)
library(copula)
sim_temp = sapply(1:m, simulate_temp)
sim_dat  = cbind(temp_data$Month[1:365], sim_temp)
AccCDD   = colSums(pmax(sim_dat[sim_dat[,1] %in% c(6,7,8),-c(1)]-18,0))
AccHDD   = colSums(pmax(18-sim_dat[sim_dat[,1] == 9,-c(1)],0))
AccRain  = rMvdc(m, copula_dist) # AccRain[1,]=QC, AccRain[2,]=Chicago
epsilon = rnorm(m ,mean=0, sd=Sigma)
design = matrix(cbind(1, training_years + 1, AccRain[,1], AccHDD, AccCDD, AccCDD^2), nrow = m, ncol = 6)
B = matrix(ols_param, nrow=6, ncol=1)
R = exp(as.vector(design %*% B)+epsilon)
par0 = c(0.25, 0.25, 0.25, 0.25, 100, 402, 50, 200)
COST = function(par0) cost(par0, R, AccRain, AccCDD, AccHDD, 'tvar', 0.10)
COST(par0)
hedge = optim(par0, COST)
p = abs(hedge$par)
return(p)
})
if(!is.null(cl)) {
stopCluster(cl)
cl = c()
}
load("annual_data.Rdata") # reload the data to have complete historic for backtesting
yld = annual_data$yield
hyld = vector()
derivatives_profit = vector()
for (i in 1:num_sim){
K1 = round(abs(p[5,i])) # contract strikes
K2 = round(abs(p[6,i]))
K3 = round(abs(p[7,i]))
K4 = round(abs(p[8,i]))
# Profit/loss on contracts
W1 = p[1,i]*(pmax(annual_data$AccRain[training_years+1] -K1,0) - price_call_rain[price_call_rain[,1]== K1,2])
W2 = p[2,i]*(pmax(annual_data$AccCDD[training_years+1] - K2,0) - price_call_cdd[price_call_cdd[,1] == K2,2])
W3 = p[3,i]*(pmax(annual_data$AccHDD9[training_years+1] - K3,0) - price_call_hdd[price_call_hdd[,1] == K3,2])
W4 = p[4,i]*(pmax(K4-annual_data$AccCDD[training_years+1],0) - price_put_cdd[price_put_cdd[,1] == K4,2])
derivatives_profit[i] = W1+W2+W3+W4
hyld[i] = yld[training_years+1]+W1+W2+W3+W4 # hedged profits
}
hyld
hyld = vector()
derivatives_profit = vector()
for (i in 1:num_sim){
K1 = round(abs(p[5,i])) # contract strikes
K2 = round(abs(p[6,i]))
K3 = round(abs(p[7,i]))
K4 = round(abs(p[8,i]))
# Profit/loss on contracts
W1 = p[1,i]*(max(annual_data$AccRain[test_year] - K1, 0) - price_call_rain[price_call_rain[,1]== K1,2])
W2 = p[2,i]*(max(annual_data$AccCDD[test_year] -  K2, 0) - price_call_cdd[price_call_cdd[,1] == K2,2])
W3 = p[3,i]*(max(annual_data$AccHDD9[test_year] - K3, 0) - price_call_hdd[price_call_hdd[,1] == K3,2])
W4 = p[4,i]*(max(K4-annual_data$AccCDD[test_year],    0) - price_put_cdd[price_put_cdd[,1] == K4,2])
derivatives_profit[i] = W1 + W2 + W3 + W4
hyld[i] = yld[test_year] + W1 + W2 + W3 + W4 # hedged profits
}
hyld
num_sim = 2
m = 10
train_size = 20
output = matrix(nr = m, nc = 50)
yield_model = lm(lyield~t+AccRain5+AccHDD9+AccCDD+sqAccCDD, data = annual_data)
ols_param = coef(yield_model)
S = summary(yield_model)$sigma
S
Sigma = S$sigma
test = function(x){x*2}
test(1)
test2 = function(y){y*test(y)}
test2(1)
test2(2)
best_garch_order = function(maxM2, maxP){
eval_bic = function(par) Bic_Garch(par, deltaTemp, training_days)
order_comb = expand.grid(M2=1:maxM2,P=1:maxP)
order_mean = matrix(apply(order_comb, 1, eval_bic), nr=maxM2, nc=maxP)
order_mean = as.numeric(which(order_mean == min(order_mean), arr.ind=TRUE))
}
M2 = 3; P = 3
s1 = matrix(cbind(1, test_days, Fourier(M1, 365)), nr = 365, nc = 8) %*% matrix(seatrend_model$coefficients, nr = 8, nc =1)
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
output
end_year = 22
training_years = (end_year - train_size + 1):end_year
training_days  = ((end_year - train_size)*365 + 1):(end_year*365)
test_year = end_year + 1
test_days = (end_year*365 + 1):((end_year + 1)*365)
source('initialization.R')
source('main.R')
sim_temp = sapply(1:m, simulate_temp)
sim_temp
s1 = matrix(cbind(1, test_days, Fourier(M1, 365)), nr = 365, nc = 8) %*% matrix(seatrend_model$coefficients, nr = 8, nc =1)
s1
s2 = colSums(M2s*t(Fourier(M2,length(training_days))))
s2
Ez=sqrt(2/pi)
sdhat = as.numeric(sigma(egarchfit))
sdhat
lag = ((end_year-1)*365 + 1):((end_year-1)*365+P)
lag
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1] = log(sdhat[lag[3]]^2)
lsigma2[1]
sdhat
sdhat[lag[3]]
lsigma2[1] = log(sdhat[365*20]^2)
lsigma2[1]
lsigma2[1] = log(sdhat[365*20+1]^2)
lsigma2[1]
simulate_temp = function(i) {
# index of initial values of the year to forecast
lag = ((end_year-1)*365 + 1):((end_year-1)*365+P)
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1] = log(sdhat[365*20]^2)
sim_deltaTemp = matrix(nr=365,nc=1)
sim_deltaTemp[1:P] = deltaTemp[lag]
sim_temp = vector(length = 365)
sim_temp[1:P] = temp_data$Mean[lag]
z = rsnorm(365, xi = skew)
for (i in (P+1):365){
AR[i] = rho %*% sim_deltaTemp[(i-1):(i-P)]
lsigma2[i] = s2[i] + omega + alpha*z[i-1] + gamma*(abs(z[i-1])-Ez) + beta*lsigma2[i-1]
sim_temp[i] = s1[i] + AR[i] + exp(lsigma2[i]/2)*z[i]
sim_deltaTemp[i] = sim_temp[i]-s1[i]
}
return(sim_temp)
}
sim_temp = sapply(1:m, simulate_temp)
sim_temp
lsigma2[1]
lag = ((end_year-1)*365 + 1):((end_year-1)*365+P)
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1] = log(sdhat[365*20]^2)
lsigma2[1]
sim_deltaTemp = matrix(nr=365,nc=1)
sim_deltaTemp[1:P] = deltaTemp[lag]
sim_deltaTemp
lag = ((train_size-1)*365 + 1):((train_size-1)*365+P)
simulate_temp = function(i) {
# index of initial values of the year to forecast
lag = ((train_size-1)*365 + 1):((train_size-1)*365+P)
AR = vector(length=365)
lsigma2 = vector(length = 365)
lsigma2[1] = log(sdhat[365*train_size]^2)
sim_deltaTemp = matrix(nr=365,nc=1)
sim_deltaTemp[1:P] = deltaTemp[lag]
sim_temp = vector(length = 365)
sim_temp[1:P] = temp_data$Mean[lag]
z = rsnorm(365, xi = skew)
for (i in (P+1):365){
AR[i] = rho %*% sim_deltaTemp[(i-1):(i-P)]
lsigma2[i] = s2[i] + omega + alpha*z[i-1] + gamma*(abs(z[i-1])-Ez) + beta*lsigma2[i-1]
sim_temp[i] = s1[i] + AR[i] + exp(lsigma2[i]/2)*z[i]
sim_deltaTemp[i] = sim_temp[i]-s1[i]
}
return(sim_temp)
}
sim_temp = sapply(1:m, simulate_temp)
sim_temp
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
output
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
output
runif
runif(1)
runif(1)
price_call_cdd
price_put_cdd
price_call_hdd
price_call_rain
source('~/Desktop/Machine Learning Project/Stage de recherche/launcher.R', echo=TRUE)
output
plot(colMeans(output))
plot(colMeans(output), type = 'l')
output[, 1:20] = annual_data$yield[1:20]
plot(colMeans(output), type = 'l')
annual_data$yield[1:20]
plot(annual_data$yield)
output
x = colMeans(output)
x[1:20]
x
x[1:20] = annual_data$yield[1:20]
plot(x, type = 'l')
lines(annual_data$yield)
View(annual_data)
